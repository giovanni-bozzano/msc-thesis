\chapter{Experiments}
\label{ch:experiments}

In this chapter we cover the experiments performed on CBT and LKT-FM. We describe the datasets and data splits, the used hyperparamenters and the goals of the experiments.\\
The \cite{10.1145/2645710.2645769}, second and third sections cover the new ranking experiments performed on CBT and LKT-FM.



\section{CBT: Experiments on Preprocessed Datasets}

The following section covers CBT raking experiments performed on the preprocessed datasets used by Cremonesi and Quadrana in their experiments \cite{10.1145/2645710.2645769}.\\
Experiments are run over 3 folds for each combination of source and target domains.\\
A bayesian optimization process is performed on each fold by using the validation set, with 50 iterations and 15 random starts. The final iteration is performed using the test set with the hyperparameters of the best iteration. The kNN phase is performed with both Pearson and cosine similarities. The metrics of its results are reported with a cutoff of 20.\\
To compare the results, the following baseline recommender systems are used with the same datasets:
\begin{itemize}
\item \textbf{Random}: random items are chosen for recommendation.
\item \textbf{TopPop}: the most popular items are chosen for recommendation.
\item \textbf{kNN}: the same kNN approach used in CBT is applied, without codebook transfer, on the original target dataset. Both Pearson and cosine similarities are used and bayesian optimization is applied.
\item \textbf{CBTf}: codebook construction, codebook transfer and kNN are applied like in CBT, but the codebook is extracted from the target domain. Both Pearson and cosine similarities are used and bayesian optimization is applied.
\end{itemize}


\subsection{Datasets}

\begin{itemize}
\item \textbf{MovieLens 1M} \cite{movielens-1m-dataset, 10.1145/1864708.1864721}: 1,000,000 ratings by 6,040 users on 3,883 movies, with range 1 to 5.
\item \textbf{Netflix Prize} \cite{netflix-prize-dataset, 10.1145/1864708.1864721}: 100,480,507 ratings by 480,189 users on 17,770 movies, with range 1 to 5.
\item \textbf{BookCrossing} \cite{10.1145/1060745.1060754}: 1,157,112 ratings by  278,858 users on 271,379 books, with range 1 to 10, normalized to be in range 1 to 5.
\end{itemize}
All datasets are preprocessed by Cremonesi and Quadrana to extract sparse and dense versions.\\
MovieLens 1M and Netflix Prize are used as source domain, while each dataset is used as target domain.\\
Each missing rating of the source domain is filled with the average of ratings of its user.\\
Finally, the preprocessed datasets used in the experiments have the following properties:\\
\begin{center}
\begin{tabulary}{1.0\textwidth}{|L|CCCC|}
\hline
\multicolumn{5}{|c|}{Source Domains} \\
\hline
& Density (\%) & Users & Items & Ratings \\
\hline
MovieLens 1M Dense & 45.18 & 500 & 500 & 112954 \\
MovieLens 1M Sparse & 14.96 & 500 & 500 & 37399 \\
Netflix Prize Dense & 48.07 & 500 & 500 & 120163 \\
Netflix Prize Sparse & 10.29 & 500 & 500 & 25714 \\
\hline
\hline
\multicolumn{5}{|c|}{Target Domains} \\
\hline
& Density (\%) & Users & Items & Ratings \\
\hline
MovieLens 1M Dense & 44.95 & 500 & 1000 & 224745 \\
MovieLens 1M Sparse & 15.24 & 500 & 1000 & 76179 \\
Netflix Prize Dense & 47.29 & 500 & 1000 & 236453 \\
Netflix Prize Sparse & 10.54 & 500 & 1000 & 52720 \\
BookCrossing & 3.03 & 500 & 1000 & 15148 \\
\hline
\end{tabulary}
\end{center}
Each target dataset is split in train, validation and test sets. To do so, a random rating for each user is removed from the dataset and added to the validation set. The same is done for the test set, while the remaining ratings form the train set.


\subsection{Hyperparameters}

The following hyperparameters are set:
\begin{itemize}
\item $\texttt{construct\_validation\_every\_n} = 1$: the amount of iterations after which the codebook construction loss is evaluated by the early stopping training for codebook construction.
\item $\texttt{construct\_lower\_validations\_allowed} = 2000$: the amount of consecutive iterations with loss higher than the best one after which the early stopping training for codebook construction stops.
\item $\texttt{maximum\_construct\_iterations} = 20000$: the maximum amount of iterations used for codebook constructions. If the early stopping training reaches this amount, it stops.
\item $\texttt{transfer\_attempts} = 3$: the amount of attempts to find a local minimum for codebook transfer.
\item $\texttt{maximum\_fill\_iterations} = 100$: the maximum amount of iterations used to find a mapping between the target domain and the codebook. The maximum amount is the same for each of the transfer attempts.
\end{itemize}
The following hyperparameters are optimized with bayesian optimization, with 50 iterations and 15 random starts:
\begin{itemize}
\item $\texttt{user\_clusters} = [5,100]$: the amount of user clusters used to build the codebook.
\item $\texttt{item\_clusters} = [5,100]$: the amount of item clusters used to build the codebook.
\item $\texttt{knn\_topk} = [5,1000]$: the amount of similar users to consider when computing similarity for kNN.
\item $\texttt{knn\_shrink} = [0,1000]$: the shrinkage to apply when computing the similarity for kNN.
\item $\texttt{knn\_similarity} = \{pearson,cosine\}$: the similarity type to use for kNN.
\item $\texttt{knn\_normalize} = \{true,false\}$: whether to normalize when computing the similarity for kNN. Normalization is computed by dividing the dot product by the product of the norms.
\end{itemize}


\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 1M (Dense) $\rightarrow$ BookCrossing} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0202} & \textbf{0.0357} & \textbf{0.0047} & \textbf{0.0940} & 0.0235 & 0.0400 \\
Random & 0.0054 & 0.0082 & 0.0009 & 0.0180 & \textbf{0.8197} & \textbf{1.0000} \\
kNN P. & \textbf{0.0372} & \textbf{0.0584} & \textbf{0.0067} & \textbf{0.1340} & 0.1181 & 0.4680 \\
kNN C. & \textbf{0.0454} & \textbf{0.0694} & \textbf{0.0077} & \textbf{0.1540} & \textbf{0.5051} & \textbf{0.9460} \\
CBTf P. & 0.0153 & 0.0236 & 0.0027 & 0.0540 & 0.1363 & 0.5040 \\
CBTf C. & 0.0116 & 0.0206 & 0.0027 & 0.0540 & 0.0226 & 0.0360 \\
CBT P. & 0.0149 & 0.0226 & 0.0025 & 0.0500 & 0.2717 & 0.8900 \\
CBT C. & 0.0152 & 0.0238 & 0.0027 & 0.0540 & 0.2227 & 0.8540 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0147 & 0.0260 & 0.0035 & 0.0700 & 0.0236 & 0.0400 \\
Random & 0.0046 & 0.0088 & 0.0012 & 0.0240 & \textbf{0.8193} & \textbf{1.0000} \\
kNN P. & 0.0322 & 0.0451 & 0.0046 & 0.0920 & 0.1164 & 0.4710 \\
kNN C. & \textbf{0.0535} & \textbf{0.0801} & \textbf{0.0090} & \textbf{0.1800} & 0.0927 & 0.3620 \\
CBTf P. & 0.0123 & 0.0220 & 0.0029 & 0.0580 & 0.1485 & 0.5810 \\
CBTf C. & 0.0111 & 0.0206 & 0.0028 & 0.0560 & 0.0225 & 0.0390 \\
CBT P. & 0.0399 & 0.0577 & 0.0062 & 0.1240 & 0.1629 & 0.6090 \\
CBT C. & 0.0175 & 0.0251 & 0.0027 & 0.0540 & 0.2281 & 0.8170 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0172} & \textbf{0.0313} & \textbf{0.0042} & \textbf{0.0840} & 0.0236 & 0.0390 \\
Random & 0.0047 & 0.0079 & 0.0010 & 0.0200 & \textbf{0.8199} & \textbf{1.0000} \\
kNN P. & \textbf{0.0383} & \textbf{0.0594} & \textbf{0.0068} & \textbf{0.1360} & 0.1132 & 0.4530 \\
kNN C. & \textbf{0.0524} & \textbf{0.0773} & \textbf{0.0084} & \textbf{0.1680} & 0.0944 & 0.3630 \\
CBTf P. & 0.0155 & 0.0270 & 0.0035 & 0.0700 & 0.0235 & 0.0470 \\
CBTf C. & 0.0147 & 0.0248 & 0.0031 & 0.0620 & 0.0231 & 0.0370 \\
CBT P. & 0.0097 & 0.0166 & 0.0021 & 0.0420 & 0.2215 & 0.6680 \\
CBT C. & 0.0101 & 0.0164 & 0.0020 & 0.0400 & 0.0220 & 0.0350 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on BookCrossing, with MovieLens 1M (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 1M (Dense) $\rightarrow$ BookCrossing} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0158 $\pm$ 0.0012 & \\
\hline
Random & 0.0049 $\pm$ 0.0004 & True \\
TopPop & 0.0174 $\pm$ 0.0023 & False \\
kNN P. & 0.0359 $\pm$ 0.0026 & True \\
kNN C. & 0.0504 $\pm$ 0.0036 & True \\
CBTf P. & 0.0124 $\pm$ 0.0023 & False \\
CBTf C. & 0.0109 $\pm$ 0.0006 & True \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0234 $\pm$ 0.0116 & \\
\hline
Random & 0.0049 $\pm$ 0.0004 & False \\
TopPop & 0.0174 $\pm$ 0.0023 & False \\
kNN P. & 0.0359 $\pm$ 0.0026 & False \\
kNN C. & 0.0504 $\pm$ 0.0036 & False \\
CBTf P. & 0.0124 $\pm$ 0.0023 & False \\
CBTf C. & 0.0109 $\pm$ 0.0006 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on BookCrossing, with MovieLens 1M (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 1M (Dense) $\rightarrow$ Netflix Prize (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0491 & 0.0791 & \textbf{0.0094} & \textbf{0.1880} & 0.1342 & 0.2930 \\
Random & 0.0079 & 0.0172 & 0.0026 & 0.0520 & \textbf{0.7321} & \textbf{1.0000} \\
kNN P. & \textbf{0.0576} & \textbf{0.0962} & \textbf{0.0119} & \textbf{0.2380} & \textbf{0.3019} & \textbf{0.7140} \\
kNN C. & \textbf{0.0709} & \textbf{0.1163} & \textbf{0.0142} & \textbf{0.2840} & \textbf{0.4775} & \textbf{0.9250} \\
CBTf P. & 0.0416 & 0.0619 & 0.0068 & 0.1360 & 0.1739 & 0.6020 \\
CBTf C. & 0.0375 & 0.0543 & 0.0057 & 0.1140 & 0.0743 & 0.1730 \\
CBT P. & 0.0544 & 0.0792 & 0.0085 & 0.1700 & 0.2450 & 0.6950 \\
CBT C. & 0.0419 & 0.0613 & 0.0065 & 0.1300 & 0.0862 & 0.2020 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0444} & \textbf{0.0688} & \textbf{0.0078} & \textbf{0.1560} & 0.1342 & 0.2920 \\
Random & 0.0056 & 0.0130 & 0.0021 & 0.0420 & \textbf{0.7324} & \textbf{1.0000} \\
kNN P. & \textbf{0.0630} & \textbf{0.0917} & \textbf{0.0098} & \textbf{0.1960} & 0.1854 & 0.4540 \\
kNN C. & \textbf{0.0876} & \textbf{0.1234} & \textbf{0.0126} & \textbf{0.2520} & 0.3787 & 0.8560 \\
CBTf P. & 0.0175 & 0.0299 & 0.0037 & 0.0740 & 0.5095 & 0.9690 \\
CBTf C. & 0.0265 & 0.0397 & 0.0044 & 0.0880 & 0.0735 & 0.1720 \\
CBT P. & 0.0443 & 0.0673 & 0.0075 & 0.1500 & 0.1725 & 0.4960 \\
CBT C. & 0.0318 & 0.0504 & 0.0060 & 0.1200 & 0.0962 & 0.2260 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0364} & \textbf{0.0616} & \textbf{0.0078} & \textbf{0.1560} & 0.1344 & 0.2920 \\
Random & 0.0101 & 0.0163 & 0.0020 & 0.0400 & \textbf{0.7327} & \textbf{1.0000} \\
kNN P. & \textbf{0.0461} & \textbf{0.0729} & \textbf{0.0086} & \textbf{0.1720} & \textbf{0.1987} & 0.5010 \\
kNN C. & \textbf{0.0636} & \textbf{0.0939} & \textbf{0.0103} & \textbf{0.2060} & \textbf{0.3826} & \textbf{0.8510} \\
CBTf P. & 0.0230 & 0.0411 & 0.0054 & 0.1080 & 0.1525 & 0.5060 \\
CBTf C. & 0.0247 & 0.0390 & 0.0045 & 0.0900 & 0.0714 & 0.1600 \\
CBT P. & 0.0301 & 0.0538 & 0.0070 & 0.1400 & 0.1466 & 0.4490 \\
CBT C. & 0.0269 & 0.0451 & 0.0056 & 0.1120 & 0.0890 & 0.2060 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Netflix Prize (Dense), with MovieLens 1M (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 1M (Dense) $\rightarrow$ Netflix Prize (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0335 $\pm$ 0.0062 & \\
\hline
Random & 0.0078 $\pm$ 0.0018 & True \\
TopPop & 0.0433 $\pm$ 0.0052 & True \\
kNN P. & 0.0556 $\pm$ 0.0070 & True \\
kNN C. & 0.0740 $\pm$ 0.0101 & True \\
CBTf P. & 0.0273 $\pm$ 0.0103 & False \\
CBTf C. & 0.0296 $\pm$ 0.0057 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0430 $\pm$ 0.0100 & \\
\hline
Random & 0.0078 $\pm$ 0.0018 & True \\
TopPop & 0.0433 $\pm$ 0.0052 & False \\
kNN P. & 0.0556 $\pm$ 0.0070 & False \\
kNN C. & 0.0740 $\pm$ 0.0101 & False \\
CBTf P. & 0.0273 $\pm$ 0.0103 & False \\
CBTf C. & 0.0296 $\pm$ 0.0057 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Netflix Prize (Dense), with MovieLens 1M (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 1M (Sparse) $\rightarrow$ BookCrossing} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0253 & 0.0408 & 0.0049 & 0.0980 & 0.0235 & 0.0400 \\
Random & 0.0038 & 0.0077 & 0.0011 & 0.0220 & \textbf{0.8197} & \textbf{1.0000} \\
kNN P. & 0.0402 & 0.0599 & 0.0065 & 0.1300 & 0.1083 & 0.4550 \\
kNN C. & \textbf{0.0588} & \textbf{0.0858} & \textbf{0.0091} & \textbf{0.1820} & 0.1314 & 0.4630 \\
CBTf P. & 0.0216 & 0.0340 & 0.0040 & 0.0800 & 0.3104 & 0.8070 \\
CBTf C. & 0.0137 & 0.0215 & 0.0026 & 0.0520 & 0.0219 & 0.0330 \\
CBT P. & 0.0584 & 0.0844 & 0.0088 & 0.1760 & 0.1642 & 0.5830 \\
CBT C. & 0.0218 & 0.0364 & 0.0045 & 0.0900 & 0.2666 & 0.8490 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0225 & 0.0343 & 0.0039 & 0.0780 & 0.0236 & 0.0400 \\
Random & 0.0065 & 0.0090 & 0.0009 & 0.0180 & \textbf{0.8199} & \textbf{1.0000} \\
kNN P. & 0.0383 & 0.0581 & 0.0065 & 0.1300 & 0.1135 & 0.4490 \\
kNN C. & 0.0394 & 0.0611 & 0.0070 & 0.1400 & \textbf{0.3057} & \textbf{0.8240} \\
CBTf P. & 0.0182 & 0.0304 & 0.0037 & 0.0740 & 0.1055 & 0.4610 \\
CBTf C. & 0.0140 & 0.0218 & 0.0025 & 0.0500 & 0.0221 & 0.0320 \\
CBT P. & \textbf{0.0399} & \textbf{0.0625} & \textbf{0.0072} & \textbf{0.1440} & 0.2540 & 0.7440 \\
CBT C. & 0.0387 & 0.0566 & 0.0060 & 0.1200 & 0.1188 & 0.6240 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0249 & 0.0407 & 0.0050 & 0.1000 & 0.0236 & 0.0390 \\
Random & 0.0037 & 0.0075 & 0.0011 & 0.0220 & \textbf{0.8193} & \textbf{1.0000} \\
kNN P. & 0.0444 & 0.0628 & 0.0064 & 0.1280 & 0.1137 & 0.4520 \\
kNN C. & \textbf{0.0620} & \textbf{0.0901} & \textbf{0.0096} & \textbf{0.1920} & 0.1753 & 0.5620 \\
CBTf P. & 0.0170 & 0.0291 & 0.0036 & 0.0720 & 0.0344 & 0.1140 \\
CBTf C. & 0.0143 & 0.0217 & 0.0025 & 0.0500 & 0.0221 & 0.0370 \\
CBT P. & 0.0514 & 0.0757 & 0.0081 & 0.1620 & 0.1630 & 0.5560 \\
CBT C. & 0.0223 & 0.0356 & 0.0042 & 0.0840 & 0.2918 & 0.8440 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on BookCrossing, with MovieLens 1M (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 1M (Sparse) $\rightarrow$ BookCrossing} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0276 $\pm$ 0.0079 & \\
\hline
Random & 0.0046 $\pm$ 0.0013 & False \\
TopPop & 0.0242 $\pm$ 0.0013 & False \\
kNN P. & 0.0410 $\pm$ 0.0026 & False \\
kNN C. & 0.0534 $\pm$ 0.0100 & False \\
CBTf P. & 0.0189 $\pm$ 0.0020 & False \\
CBTf C. & 0.0140 $\pm$ 0.0002 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0499 $\pm$ 0.0076 & \\
\hline
Random & 0.0046 $\pm$ 0.0013 & True \\
TopPop & 0.0242 $\pm$ 0.0013 & True \\
kNN P. & 0.0410 $\pm$ 0.0026 & False \\
kNN C. & 0.0534 $\pm$ 0.0100 & False \\
CBTf P. & 0.0189 $\pm$ 0.0020 & True \\
CBTf C. & 0.0140 $\pm$ 0.0002 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on BookCrossing, with MovieLens 1M (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 1M (Sparse) $\rightarrow$ Netflix Prize (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0364 & 0.0580 & 0.0069 & 0.1380 & 0.0362 & 0.1290 \\
Random & 0.0036 & 0.0065 & 0.0009 & 0.0180 & \textbf{0.8097} & \textbf{1.0000} \\
kNN P. & \textbf{0.0525} & \textbf{0.0780} & 0.0085 & 0.1700 & 0.0674 & 0.1980 \\
kNN C. & \textbf{0.0593} & \textbf{0.0937} & \textbf{0.0109} & \textbf{0.2180} & 0.0844 & 0.2460 \\
CBTf P. & 0.0148 & 0.0277 & 0.0038 & 0.0760 & 0.2458 & 0.7620 \\
CBTf C. & 0.0148 & 0.0300 & 0.0044 & 0.0880 & 0.0318 & 0.0870 \\
CBT P. & 0.0396 & 0.0673 & 0.0085 & 0.1700 & 0.0643 & 0.3010 \\
CBT C. & 0.0250 & 0.0440 & 0.0058 & 0.1160 & 0.0349 & 0.1240 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0490 & 0.0727 & 0.0080 & 0.1600 & 0.0361 & 0.1270 \\
Random & 0.0034 & 0.0061 & 0.0008 & 0.0160 & \textbf{0.8091} & \textbf{1.0000} \\
kNN P. & 0.0523 & 0.0819 & 0.0095 & 0.1900 & 0.0800 & 0.2360 \\
kNN C. & \textbf{0.0769} & \textbf{0.1158} & \textbf{0.0128} & \textbf{0.2560} & 0.1609 & 0.4600 \\
CBTf P. & 0.0287 & 0.0449 & 0.0053 & 0.1060 & 0.1008 & 0.5000 \\
CBTf C. & 0.0255 & 0.0412 & 0.0050 & 0.1000 & 0.0319 & 0.0850 \\
CBT P. & 0.0600 & 0.0893 & 0.0097 & 0.1940 & 0.0665 & 0.2950 \\
CBT C. & 0.0531 & 0.0815 & 0.0092 & 0.1840 & 0.3219 & 0.8170 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0320 & 0.0520 & 0.0063 & 0.1260 & 0.0362 & 0.1290 \\
Random & 0.0030 & 0.0070 & 0.0011 & 0.0220 & \textbf{0.8093} & \textbf{1.0000} \\
kNN P. & \textbf{0.0533} & \textbf{0.0832} & \textbf{0.0096} & \textbf{0.1920} & \textbf{0.1465} & \textbf{0.4420} \\
kNN C. & \textbf{0.0648} & \textbf{0.1010} & \textbf{0.0117} & \textbf{0.2340} & \textbf{0.1574} & \textbf{0.4450} \\
CBTf P. & 0.0165 & 0.0280 & 0.0035 & 0.0700 & 0.0643 & 0.3450 \\
CBTf C. & 0.0181 & 0.0327 & 0.0044 & 0.0880 & 0.0317 & 0.0820 \\
CBT P. & 0.0451 & 0.0690 & 0.0079 & 0.1580 & 0.0676 & 0.3430 \\
CBT C. & 0.0245 & 0.0399 & 0.0049 & 0.0980 & 0.0343 & 0.1180 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Netflix Prize (Sparse), with MovieLens 1M (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 1M (Sparse) $\rightarrow$ Netflix Prize (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0342 $\pm$ 0.0134 & \\
\hline
Random & 0.0033 $\pm$ 0.0003 & False \\
TopPop & 0.0392 $\pm$ 0.0072 & False \\
kNN P. & 0.0527 $\pm$ 0.0005 & False \\
kNN C. & 0.0670 $\pm$ 0.0074 & False \\
CBTf P. & 0.0200 $\pm$ 0.0062 & False \\
CBTf C. & 0.0195 $\pm$ 0.0045 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0482 $\pm$ 0.0086 & \\
\hline
Random & 0.0033 $\pm$ 0.0003 & True \\
TopPop & 0.0392 $\pm$ 0.0072 & False \\
kNN P. & 0.0527 $\pm$ 0.0005 & False \\
kNN C. & 0.0670 $\pm$ 0.0074 & True \\
CBTf P. & 0.0200 $\pm$ 0.0062 & True \\
CBTf C. & 0.0195 $\pm$ 0.0045 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Netflix Prize (Sparse), with MovieLens 1M (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize (Dense) $\rightarrow$ BookCrossing} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0260 & 0.0402 & 0.0046 & 0.0920 & 0.0236 & 0.0400 \\
Random & 0.0046 & 0.0078 & 0.0010 & 0.0200 & \textbf{0.8199} & \textbf{1.0000} \\
kNN P. & 0.0307 & 0.0512 & 0.0063 & 0.1260 & 0.1208 & 0.4790 \\
kNN C. & \textbf{0.0491} & \textbf{0.0748} & \textbf{0.0084} & \textbf{0.1680} & 0.1327 & 0.4680 \\
CBTf P. & 0.0182 & 0.0284 & 0.0032 & 0.0640 & 0.1658 & 0.5800 \\
CBTf C. & 0.0115 & 0.0178 & 0.0020 & 0.0400 & 0.0223 & 0.0330 \\
CBT P. & 0.0432 & 0.0681 & 0.0079 & 0.1580 & 0.0940 & 0.3750 \\
CBT C. & 0.0271 & 0.0468 & 0.0059 & 0.1180 & 0.2428 & 0.8000 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0104 & 0.0249 & 0.0040 & 0.0800 & 0.0235 & 0.0400 \\
Random & 0.0039 & 0.0082 & 0.0012 & 0.0240 & \textbf{0.8196} & \textbf{1.0000} \\
kNN P. & 0.0332 & 0.0557 & 0.0069 & 0.1380 & 0.0999 & 0.4330 \\
kNN C. & \textbf{0.0527} & \textbf{0.0796} & \textbf{0.0088} & \textbf{0.1760} & 0.1076 & 0.4020 \\
CBTf P. & 0.0133 & 0.0209 & 0.0024 & 0.0480 & 0.2209 & 0.6600 \\
CBTf C. & 0.0068 & 0.0102 & 0.0011 & 0.0220 & 0.0218 & 0.0310 \\
CBT P. & 0.0403 & 0.0628 & 0.0072 & 0.1440 & 0.0895 & 0.3680 \\
CBT C. & 0.0233 & 0.0349 & 0.0039 & 0.0780 & 0.1991 & 0.7690 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0180 & 0.0316 & 0.0042 & 0.0840 & 0.0236 & 0.0410 \\
Random & 0.0032 & 0.0064 & 0.0009 & 0.0180 & \textbf{0.8196} & \textbf{1.0000} \\
kNN P. & 0.0351 & 0.0574 & 0.0070 & 0.1400 & \textbf{0.1104} & \textbf{0.4700} \\
kNN C. & \textbf{0.0657} & \textbf{0.0953} & \textbf{0.0101} & \textbf{0.2020} & \textbf{0.1097} & \textbf{0.4020} \\
CBTf P. & 0.0116 & 0.0197 & 0.0025 & 0.0500 & 0.0463 & 0.1470 \\
CBTf C. & 0.0146 & 0.0230 & 0.0027 & 0.0540 & 0.0226 & 0.0370 \\
CBT P. & 0.0353 & 0.0622 & 0.0081 & 0.1620 & 0.0602 & 0.3090 \\
CBT C. & 0.0178 & 0.0302 & 0.0039 & 0.0780 & 0.0233 & 0.0370 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on BookCrossing, with Netflix Prize (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Dense) $\rightarrow$ BookCrossing} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0227 $\pm$ 0.0038 & \\
\hline
Random & 0.0039 $\pm$ 0.0006 & True \\
TopPop & 0.0181 $\pm$ 0.0064 & False \\
kNN P. & 0.0330 $\pm$ 0.0018 & False \\
kNN C. & 0.0558 $\pm$ 0.0071 & True \\
CBTf P. & 0.0144 $\pm$ 0.0028 & True \\
CBTf C. & 0.0110 $\pm$ 0.0032 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0396 $\pm$ 0.0032 & \\
\hline
Random & 0.0039 $\pm$ 0.0006 & True \\
TopPop & 0.0181 $\pm$ 0.0064 & True \\
kNN P. & 0.0330 $\pm$ 0.0018 & False \\
kNN C. & 0.0558 $\pm$ 0.0071 & False \\
CBTf P. & 0.0144 $\pm$ 0.0028 & True \\
CBTf C. & 0.0110 $\pm$ 0.0032 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on BookCrossing, with Netflix Prize (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize (Dense) $\rightarrow$ MovieLens 1M (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0550 & 0.0793 & 0.0085 & 0.1700 & 0.1308 & 0.3030 \\
Random & 0.0084 & 0.0159 & 0.0022 & 0.0440 & \textbf{0.7498} & \textbf{0.9900} \\
kNN P. & \textbf{0.0693} & \textbf{0.0966} & \textbf{0.0098} & \textbf{0.1960} & 0.2516 & 0.6730 \\
kNN C. & \textbf{0.0917} & \textbf{0.1356} & \textbf{0.0148} & \textbf{0.2960} & \textbf{0.5049} & \textbf{0.9480} \\
CBTf P. & 0.0511 & 0.0692 & 0.0067 & 0.1340 & 0.1514 & 0.5290 \\
CBTf C. & 0.0423 & 0.0597 & 0.0061 & 0.1220 & 0.0787 & 0.2200 \\
CBT P. & 0.0609 & 0.0849 & 0.0085 & 0.1700 & 0.1923 & 0.5590 \\
CBT C. & 0.0382 & 0.0585 & 0.0066 & 0.1320 & 0.4403 & 0.8830 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0555 & 0.0779 & 0.0079 & 0.1580 & 0.1307 & 0.3050 \\
Random & 0.0091 & 0.0142 & 0.0017 & 0.0340 & \textbf{0.7507} & \textbf{0.9890} \\
kNN P. & \textbf{0.0732} & \textbf{0.1095} & \textbf{0.0121} & \textbf{0.2420} & \textbf{0.2435} & 0.6400 \\
kNN C. & \textbf{0.1050} & \textbf{0.1433} & \textbf{0.0141} & \textbf{0.2820} & \textbf{0.4658} & \textbf{0.9100} \\
CBTf P. & 0.0465 & 0.0651 & 0.0065 & 0.1300 & 0.2346 & 0.7120 \\
CBTf C. & 0.0391 & 0.0540 & 0.0055 & 0.1100 & 0.0779 & 0.2220 \\
CBT P. & 0.0577 & 0.0827 & 0.0087 & 0.1740 & 0.2313 & 0.6590 \\
CBT C. & 0.0455 & 0.0616 & 0.0060 & 0.1200 & 0.1044 & 0.2780 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0522} & \textbf{0.0784} & \textbf{0.0087} & \textbf{0.1740} & 0.1305 & 0.3060 \\
Random & 0.0116 & 0.0195 & 0.0024 & 0.0480 & \textbf{0.7506} & \textbf{0.9890} \\
kNN P. & \textbf{0.0628} & \textbf{0.0983} & \textbf{0.0113} & \textbf{0.2260} & \textbf{0.2870} & \textbf{0.7490} \\
kNN C. & \textbf{0.0851} & \textbf{0.1279} & \textbf{0.0140} & \textbf{0.2800} & \textbf{0.2764} & \textbf{0.7790} \\
CBTf P. & 0.0363 & 0.0527 & 0.0056 & 0.1120 & 0.2022 & 0.6520 \\
CBTf C. & 0.0304 & 0.0489 & 0.0058 & 0.1160 & 0.0786 & 0.2230 \\
CBT P. & 0.0490 & 0.0753 & 0.0085 & 0.1700 & 0.1812 & 0.5490 \\
CBT C. & 0.0337 & 0.0540 & 0.0064 & 0.1280 & 0.0880 & 0.2370 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on MovieLens 1M (Dense), with Netflix Prize (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Dense) $\rightarrow$ MovieLens 1M (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0391 $\pm$ 0.0048 & \\
\hline
Random & 0.0097 $\pm$ 0.0014 & True \\
TopPop & 0.0542 $\pm$ 0.0015 & True \\
kNN P. & 0.0684 $\pm$ 0.0043 & True \\
kNN C. & 0.0939 $\pm$ 0.0082 & True \\
CBTf P. & 0.0447 $\pm$ 0.0062 & False \\
CBTf C. & 0.0373 $\pm$ 0.0050 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0559 $\pm$ 0.0051 & \\
\hline
Random & 0.0097 $\pm$ 0.0014 & True \\
TopPop & 0.0542 $\pm$ 0.0015 & False \\
kNN P. & 0.0684 $\pm$ 0.0043 & True \\
kNN C. & 0.0939 $\pm$ 0.0082 & True \\
CBTf P. & 0.0447 $\pm$ 0.0062 & True \\
CBTf C. & 0.0373 $\pm$ 0.0050 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on MovieLens 1M (Dense), with Netflix Prize (Dense) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize (Sparse) $\rightarrow$ BookCrossing} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0248 & 0.0414 & 0.0051 & 0.1020 & 0.0235 & 0.0410 \\
Random & 0.0026 & 0.0073 & 0.0013 & 0.0260 & \textbf{0.8197} & \textbf{1.0000} \\
kNN P. & 0.0451 & 0.0671 & 0.0073 & 0.1460 & 0.1220 & 0.4780 \\
kNN C. & \textbf{0.0520} & \textbf{0.0773} & 0.0085 & 0.1700 & \textbf{0.2612} & 0.7130 \\
CBTf P. & 0.0182 & 0.0284 & 0.0032 & 0.0640 & 0.0371 & 0.1670 \\
CBTf C. & 0.0208 & 0.0317 & 0.0035 & 0.0700 & 0.0226 & 0.0380 \\
CBT P. & 0.0495 & 0.0760 & \textbf{0.0086} & \textbf{0.1720} & 0.1626 & 0.5720 \\
CBT C. & 0.0137 & 0.0212 & 0.0024 & 0.0480 & 0.2355 & 0.8250 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0230 & 0.0340 & 0.0037 & 0.0740 & 0.0236 & 0.0390 \\
Random & 0.0003 & 0.0007 & 0.0001 & 0.0020 & \textbf{0.8196} & \textbf{1.0000} \\
kNN P. & 0.0401 & 0.0577 & 0.0061 & 0.1220 & 0.0981 & 0.4250 \\
kNN C. & \textbf{0.0640} & \textbf{0.0907} & \textbf{0.0094} & \textbf{0.1880} & 0.0949 & 0.3640 \\
CBTf P. & 0.0115 & 0.0215 & 0.0029 & 0.0580 & 0.0349 & 0.1170 \\
CBTf C. & 0.0091 & 0.0110 & 0.0009 & 0.0180 & 0.0215 & 0.0330 \\
CBT P. & 0.0573 & 0.0817 & 0.0085 & 0.1700 & 0.0927 & 0.4010 \\
CBT C. & 0.0522 & 0.0725 & 0.0072 & 0.1440 & 0.2368 & 0.8020 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0192 & 0.0326 & 0.0041 & 0.0820 & 0.0235 & 0.0390 \\
Random & 0.0035 & 0.0071 & 0.0010 & 0.0200 & \textbf{0.8200} & \textbf{1.0000} \\
kNN P. & 0.0324 & 0.0480 & 0.0052 & 0.1040 & 0.1164 & 0.4640 \\
kNN C. & 0.0541 & 0.0783 & 0.0083 & 0.1660 & 0.1069 & 0.4040 \\
CBTf P. & 0.0157 & 0.0247 & 0.0029 & 0.0580 & 0.1994 & 0.6080 \\
CBTf C. & 0.0133 & 0.0234 & 0.0030 & 0.0600 & 0.0223 & 0.0320 \\
CBT P. & \textbf{0.0543} & \textbf{0.0807} & \textbf{0.0088} & \textbf{0.1760} & 0.1533 & 0.5580 \\
CBT C. & 0.0376 & 0.0580 & 0.0066 & 0.1320 & 0.1104 & 0.5320 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on BookCrossing, with Netflix Prize (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Sparse) $\rightarrow$ BookCrossing} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0345 $\pm$ 0.0159 & \\
\hline
Random & 0.0021 $\pm$ 0.0013 & False \\
TopPop & 0.0223 $\pm$ 0.0023 & False \\
kNN P. & 0.0392 $\pm$ 0.0052 & False \\
kNN C. & 0.0567 $\pm$ 0.0053 & False \\
CBTf P. & 0.0151 $\pm$ 0.0028 & False \\
CBTf C. & 0.0144 $\pm$ 0.0049 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0537 $\pm$ 0.0032 & \\
\hline
Random & 0.0021 $\pm$ 0.0013 & True \\
TopPop & 0.0223 $\pm$ 0.0023 & True \\
kNN P. & 0.0392 $\pm$ 0.0052 & False \\
kNN C. & 0.0567 $\pm$ 0.0053 & False \\
CBTf P. & 0.0151 $\pm$ 0.0028 & True \\
CBTf C. & 0.0144 $\pm$ 0.0049 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on BookCrossing, with Netflix Prize (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize (Sparse) $\rightarrow$ MovieLens 1M (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0359 & 0.0585 & 0.0071 & 0.1420 & 0.0505 & 0.1760 \\
Random & 0.0060 & 0.0093 & 0.0011 & 0.0220 & \textbf{0.8041} & \textbf{1.0000} \\
kNN P. & \textbf{0.0711} & \textbf{0.1104} & \textbf{0.0127} & \textbf{0.2540} & \textbf{0.1357} & \textbf{0.5580} \\
kNN C. & \textbf{0.0978} & \textbf{0.1443} & \textbf{0.0156} & \textbf{0.3120} & \textbf{0.2366} & \textbf{0.6330} \\
CBTf P. & 0.0289 & 0.0448 & 0.0051 & 0.1020 & 0.0436 & 0.2010 \\
CBTf C. & 0.0256 & 0.0400 & 0.0046 & 0.0920 & 0.0792 & 0.4510 \\
CBT P. & 0.0655 & 0.1047 & 0.0124 & 0.2480 & 0.0945 & 0.3280 \\
CBT C. & 0.0347 & 0.0571 & 0.0070 & 0.1400 & 0.0495 & 0.1740 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0543 & 0.0808 & 0.0088 & 0.1760 & 0.0505 & 0.1790 \\
Random & 0.0052 & 0.0097 & 0.0013 & 0.0260 & \textbf{0.8046} & \textbf{1.0000} \\
kNN P. & 0.0844 & 0.1147 & 0.0112 & 0.2240 & \textbf{0.1411} & \textbf{0.5720} \\
kNN C. & \textbf{0.1008} & \textbf{0.1427} & \textbf{0.0147} & \textbf{0.2940} & \textbf{0.1962} & \textbf{0.6650} \\
CBTf P. & 0.0390 & 0.0574 & 0.0062 & 0.1240 & 0.0741 & 0.3230 \\
CBTf C. & 0.0283 & 0.0484 & 0.0061 & 0.1220 & 0.0401 & 0.1250 \\
CBT P. & 0.0972 & 0.1313 & 0.0127 & 0.2540 & 0.1144 & 0.3960 \\
CBT C. & 0.0511 & 0.0813 & 0.0095 & 0.1900 & 0.0506 & 0.1790 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0465 & 0.0706 & 0.0079 & 0.1580 & 0.0505 & 0.1800 \\
Random & 0.0038 & 0.0059 & 0.0007 & 0.0140 & \textbf{0.8042} & \textbf{1.0000} \\
kNN P. & 0.0877 & \textbf{0.1301} & \textbf{0.0141} & \textbf{0.2820} & \textbf{0.2469} & \textbf{0.7650} \\
kNN C. & \textbf{0.1185} & \textbf{0.1711} & \textbf{0.0179} & \textbf{0.3580} & \textbf{0.2098} & 0.5990 \\
CBTf P. & 0.0423 & 0.0643 & 0.0073 & 0.1460 & 0.0458 & 0.2320 \\
CBTf C. & 0.0378 & 0.0577 & 0.0065 & 0.1300 & 0.0656 & 0.4660 \\
CBT P. & 0.0880 & 0.1210 & 0.0119 & 0.2380 & 0.2034 & 0.6830 \\
CBT C. & 0.0470 & 0.0734 & 0.0085 & 0.1700 & 0.0498 & 0.1790 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on MovieLens 1M (Sparse), with Netflix Prize (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Sparse) $\rightarrow$ MovieLens 1M (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0443 $\pm$ 0.0070 & \\
\hline
Random & 0.0050 $\pm$ 0.0009 & True \\
TopPop & 0.0456 $\pm$ 0.0075 & False \\
kNN P. & 0.0810 $\pm$ 0.0072 & True \\
kNN C. & 0.1057 $\pm$ 0.0091 & True \\
CBTf P. & 0.0367 $\pm$ 0.0057 & False \\
CBTf C. & 0.0306 $\pm$ 0.0052 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0836 $\pm$ 0.0133 & \\
\hline
Random & 0.0050 $\pm$ 0.0009 & True \\
TopPop & 0.0456 $\pm$ 0.0075 & True \\
kNN P. & 0.0810 $\pm$ 0.0072 & False \\
kNN C. & 0.1057 $\pm$ 0.0091 & False \\
CBTf P. & 0.0367 $\pm$ 0.0057 & True \\
CBTf C. & 0.0306 $\pm$ 0.0052 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on MovieLens 1M (Sparse), with Netflix Prize (Sparse) as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\clearpage



\section{CBT: Experiments on Public Datasets}

The following section covers CBT ranking experiments performed on well known datasets in the field of recommender systems.\\
Experiments are run over 3 folds for each combination of source and target domains.\\
A bayesian optimization process is performed on each fold by using the validation set, with 50 iterations and 15 random starts. The final iteration is performed using the test set with the hyperparameters of the best iteration. The kNN phase is performed with both Pearson and cosine similarities. The metrics of its results are reported with a cutoff of 20.\\
To compare the results, the following baseline recommender systems are used with the same datasets:
\begin{itemize}
\item \textbf{Random}: random items are chosen for recommendation.
\item \textbf{TopPop}: the most popular items are chosen for recommendation.
\item \textbf{kNN}: the same kNN approach used in CBT is applied, without codebook transfer, on the original target dataset. Both Pearson and cosine similarities are used and bayesian optimization is applied.
\item \textbf{CBTf}: codebook construction, codebook transfer and kNN are applied like in CBT, but the codebook is extracted from the target domain. Both Pearson and cosine similarities are used and bayesian optimization is applied.
\end{itemize}


\subsection{Datasets}

\begin{itemize}
\item \textbf{MovieLens 20M} \cite{movielens-20m-dataset}: 20,000,263 ratings by 138,493 users on 27,278 movies, with range 1 to 5.
\item \textbf{MovieLens Hetrec 2011} \cite{grouplens, hetrec-2011}: 855,598 ratings by 2,113 users on 10,109 movies, with range 1 to 5.
\item \textbf{Netflix Prize} \cite{netflix-prize-dataset, 10.1145/1864708.1864721}: 100,480,507 ratings by 480,189 users on 17,770 movies, with range 1 to 5.
\item \textbf{Amazon Movies TV Series} \cite{amazon-movies-tv-series-dataset}: 4,607,047 ratings by 2,088,620 users on 200,941 movies and TV series, with range 1 to 5.
\end{itemize}
MovieLens 20M and Netflix Prize are preprocessed to extract very dense datasets to be used as source domain.\\
MovieLens Hetrec 2011, Netflix Prize and Amazon Movies TV Series are preprocessed to extract sparse and dense versions, both to be used as target domain.\\
Preprocessing for both source and target domains is performed in multiple iterations. First by removing users with a low amount of interactions, then by removing items with a low amount of interactions. Each missing rating of the source domain is filled with the average of ratings of its user.\\
Finally, the preprocessed datasets used in the experiments have the following properties:\\
\begin{center}
\begin{tabulary}{1.0\textwidth}{|L|CCCC|}
\hline
\multicolumn{5}{|c|}{Source Domains} \\
\hline
& Density (\%) & Users & Items & Ratings \\
\hline
MovieLens 20M & 81.44 & 500 & 500 & 203610 \\
Netflix Prize & 56.77 & 500 & 500 & 141934 \\
\hline
\hline
\multicolumn{5}{|c|}{Target Domains} \\
\hline
& Density (\%) & Users & Items & Ratings \\
\hline
MovieLens Hetrec 2011 D. & 11.66 & 500 & 1000 & 58298 \\
MovieLens Hetrec 2011 S. & 2.93 & 500 & 1000 & 14627 \\
Netflix Prize D. & 11.53 & 500 & 1000 & 57656 \\
Netflix Prize S. & 3.78 & 500 & 1000 & 18904 \\
Amazon Movies TV Series D. & 10.21 & 500 & 1000 & 51048 \\
Amazon Movies TV Series S. & 2.88 & 500 & 1000 & 14416 \\
\hline
\end{tabulary}
\end{center}
Each target dataset is split in train, validation and test sets. To do so, a random rating for each user is removed from the dataset and added to the validation set. The same is done for the test set, while the remaining ratings form the train set.


\subsection{Hyperparameters}

The following hyperparameters are set:
\begin{itemize}
\item $\texttt{construct\_validation\_every\_n} = 1$: the amount of iterations after which the codebook construction loss is evaluated by the early stopping training for codebook construction.
\item $\texttt{construct\_lower\_validations\_allowed} = 2000$: the amount of consecutive iterations with loss higher than the best one after which the early stopping training for codebook construction stops.
\item $\texttt{maximum\_construct\_iterations} = 20000$: the maximum amount of iterations used for codebook constructions. If the early stopping training reaches this amount, it stops.
\item $\texttt{transfer\_attempts} = 30$: the amount of attempts to find a local minimum for codebook transfer.
\item $\texttt{maximum\_fill\_iterations} = 100$: the maximum amount of iterations used to find a mapping between the target domain and the codebook. the maximum amount is the same for each of the transfer attempts.
\end{itemize}
The following hyperparameters are optimized with bayesian optimization, with 50 iterations and 15 random starts:
\begin{itemize}
\item $\texttt{user\_clusters} = [5,100]$: the amount of user clusters used to build the codebook.
\item $\texttt{item\_clusters} = [5,100]$: the amount of item clusters used to build the codebook.
\item $\texttt{knn\_topk} = [5,1000]$: the amount of similar users to consider when computing similarity for kNN.
\item $\texttt{knn\_shrink} = [0,1000]$: the shrinkage to apply when computing the similarity for kNN.
\item $\texttt{knn\_similarity} = \{pearson,cosine\}$: the similarity type to use for kNN.
\item $\texttt{knn\_normalize} = \{true,false\}$: whether to normalize when computing the similarity for kNN. Normalization is computed by dividing the dot product by the product of the norms.
\end{itemize}


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{pictures/movielens-dense-target}
\caption{Representation of the preprocessed MovieLens Hetrec 2011 Dense train set.}
\includegraphics[width=\textwidth]{pictures/movielens-sparse-target}
\caption{Representation of the preprocessed MovieLens Hetrec 2011 Sparse train set.}
\end{figure}


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{pictures/movielens-target}
\caption{Heatmap of the preprocessed MovieLens Hetrec 2011 Dense train set.}
\includegraphics[width=\textwidth]{pictures/movielens-target-filled}
\caption{Heatmap of the preprocessed MovieLens Hetrec 2011 Dense train set filled with a codebook extracted from the Netflix Prize domain.}
\end{figure}


\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 20M $\rightarrow$ Amazon Movies TV Series (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0100 & 0.0160 & 0.0019 & 0.0380 & 0.3362 & 0.0700 \\
Random & 0.0042 & 0.0093 & 0.0014 & 0.0280 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0214} & \textbf{0.0351} & \textbf{0.0042} & \textbf{0.0840} & \textbf{0.7096} & \textbf{0.4300} \\
kNN C. & \textbf{0.0392} & \textbf{0.0630} & \textbf{0.0075} & \textbf{0.1500} & \textbf{0.9571} & \textbf{0.9440} \\
CBTf P. & 0.0107 & 0.0181 & 0.0022 & 0.0440 & 0.3730 & 0.1420 \\
CBTf C. & 0.0093 & 0.0162 & 0.0021 & 0.0420 & 0.2598 & 0.0580 \\
CBT P. & 0.0110 & 0.0199 & 0.0026 & 0.0520 & 0.3026 & 0.0740 \\
CBT C. & 0.0099 & 0.0185 & 0.0025 & 0.0500 & 0.2794 & 0.0590 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0158} & \textbf{0.0261} & \textbf{0.0032} & \textbf{0.0640} & 0.3374 & 0.0700 \\
Random & 0.0048 & 0.0110 & 0.0017 & 0.0340 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0292} & \textbf{0.0451} & \textbf{0.0051} & \textbf{0.1020} & 0.6225 & 0.2710 \\
kNN C. & \textbf{0.0528} & \textbf{0.0782} & \textbf{0.0086} & \textbf{0.1720} & 0.9256 & 0.7660 \\
CBTf P. & 0.0074 & 0.0155 & 0.0023 & 0.0460 & 0.9327 & 0.8540 \\
CBTf C. & 0.0067 & 0.0136 & 0.0020 & 0.0400 & 0.6979 & 0.3970 \\
CBT P. & 0.0047 & 0.0100 & 0.0015 & 0.0300 & 0.8546 & 0.6850 \\
CBT C. & 0.0059 & 0.0117 & 0.0017 & 0.0340 & 0.8133 & 0.8170 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0132} & \textbf{0.0237} & \textbf{0.0032} & \textbf{0.0640} & 0.3371 & 0.0700 \\
Random & 0.0051 & 0.0090 & 0.0012 & 0.0240 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0220} & \textbf{0.0362} & \textbf{0.0044} & \textbf{0.0880} & \textbf{0.8633} & \textbf{0.6630} \\
kNN C. & \textbf{0.0506} & \textbf{0.0727} & \textbf{0.0078} & \textbf{0.1560} & \textbf{0.9691} & \textbf{0.9820} \\
CBTf P. & 0.0102 & 0.0156 & 0.0018 & 0.0360 & 0.7620 & 0.5950 \\
CBTf C. & 0.0073 & 0.0142 & 0.0020 & 0.0400 & 0.7485 & 0.4200 \\
CBT P. & 0.0060 & 0.0130 & 0.0019 & 0.0380 & 0.5951 & 0.5450 \\
CBT C. & 0.0071 & 0.0150 & 0.0022 & 0.0440 & 0.2082 & 0.0550 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Amazon Movies TV Series (Dense), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 20M $\rightarrow$ Amazon Movies TV Series (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0077 $\pm$ 0.0017 & \\
\hline
Random & 0.0047 $\pm$ 0.0004 & False \\
TopPop & 0.0130 $\pm$ 0.0024 & False \\
kNN P. & 0.0242 $\pm$ 0.0036 & True \\
kNN C. & 0.0476 $\pm$ 0.0060 & True \\
CBTf P. & 0.0094 $\pm$ 0.0015 & False \\
CBTf C. & 0.0078 $\pm$ 0.0011 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0073 $\pm$ 0.0027 & \\
\hline
Random & 0.0047 $\pm$ 0.0004 & False \\
TopPop & 0.0130 $\pm$ 0.0024 & False \\
kNN P. & 0.0242 $\pm$ 0.0036 & False \\
kNN C. & 0.0476 $\pm$ 0.0060 & True \\
CBTf P. & 0.0094 $\pm$ 0.0015 & False \\
CBTf C. & 0.0078 $\pm$ 0.0011 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Amazon Movies TV Series (Dense), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 20M $\rightarrow$ Amazon Movies TV Series (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0900} & \textbf{0.1104} & \textbf{0.0094} & \textbf{0.1880} & 0.1840 & 0.0570 \\
Random & 0.0030 & 0.0062 & 0.0009 & 0.0180 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0922} & \textbf{0.1085} & \textbf{0.0083} & \textbf{0.1660} & 0.7109 & \textbf{0.6260} \\
kNN C. & \textbf{0.1045} & \textbf{0.1272} & \textbf{0.0105} & \textbf{0.2100} & 0.5186 & 0.2850 \\
CBTf P. & 0.0091 & 0.0153 & 0.0019 & 0.0380 & 0.7979 & 0.4080 \\
CBTf C. & 0.0138 & 0.0213 & 0.0024 & 0.0480 & 0.1304 & 0.0510 \\
CBT P. & 0.0663 & 0.0802 & 0.0066 & 0.1320 & 0.2823 & 0.0860 \\
CBT C. & 0.0747 & 0.0889 & 0.0071 & 0.1420 & 0.1639 & 0.0600 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0662} & \textbf{0.0871} & \textbf{0.0082} & \textbf{0.1640} & 0.1840 & 0.0580 \\
Random & 0.0042 & 0.0078 & 0.0011 & 0.0220 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0565} & \textbf{0.0743} & \textbf{0.0069} & \textbf{0.1380} & \textbf{0.7199} & \textbf{0.4710} \\
kNN C. & \textbf{0.0765} & \textbf{0.0983} & \textbf{0.0088} & \textbf{0.1760} & 0.4411 & 0.2030 \\
CBTf P. & 0.0220 & 0.0333 & 0.0038 & 0.0760 & 0.5939 & 0.3510 \\
CBTf C. & 0.0080 & 0.0154 & 0.0021 & 0.0420 & 0.6468 & 0.3200 \\
CBT P. & 0.0539 & 0.0672 & 0.0058 & 0.1160 & 0.2899 & 0.0840 \\
CBT C. & 0.0530 & 0.0648 & 0.0054 & 0.1080 & 0.1646 & 0.0580 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0824} & \textbf{0.0989} & \textbf{0.0080} & \textbf{0.1600} & 0.1842 & 0.0580 \\
Random & 0.0027 & 0.0059 & 0.0009 & 0.0180 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0756} & \textbf{0.0912} & \textbf{0.0073} & \textbf{0.1460} & \textbf{0.7250} & \textbf{0.5970} \\
kNN C. & \textbf{0.0922} & \textbf{0.1106} & \textbf{0.0087} & \textbf{0.1740} & 0.4464 & 0.2000 \\
CBTf P. & 0.0085 & 0.0136 & 0.0016 & 0.0320 & 0.6222 & 0.3170 \\
CBTf C. & 0.0129 & 0.0196 & 0.0022 & 0.0440 & 0.1283 & 0.0460 \\
CBT P. & 0.0670 & 0.0788 & 0.0061 & 0.1220 & 0.2113 & 0.0700 \\
CBT C. & 0.0647 & 0.0734 & 0.0052 & 0.1040 & 0.1611 & 0.0590 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Amazon Movies TV Series (Sparse), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 20M $\rightarrow$ Amazon Movies TV Series (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0641 $\pm$ 0.0088 & \\
\hline
Random & 0.0033 $\pm$ 0.0007 & True \\
TopPop & 0.0795 $\pm$ 0.0099 & True \\
kNN P. & 0.0748 $\pm$ 0.0146 & False \\
kNN C. & 0.0911 $\pm$ 0.0115 & True \\
CBTf P. & 0.0132 $\pm$ 0.0062 & True \\
CBTf C. & 0.0116 $\pm$ 0.0026 & True \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0624 $\pm$ 0.0060 & \\
\hline
Random & 0.0033 $\pm$ 0.0007 & True \\
TopPop & 0.0795 $\pm$ 0.0099 & True \\
kNN P. & 0.0748 $\pm$ 0.0146 & False \\
kNN C. & 0.0911 $\pm$ 0.0115 & True \\
CBTf P. & 0.0132 $\pm$ 0.0062 & True \\
CBTf C. & 0.0116 $\pm$ 0.0026 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Amazon Movies TV Series (Sparse), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 20M $\rightarrow$ Netflix Prize (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1124} & \textbf{0.1604} & \textbf{0.0170} & \textbf{0.3320} & 0.6775 & 0.2280 \\
Random & 0.0079 & 0.0156 & 0.0026 & 0.0440 & \textbf{0.9796} & \textbf{0.9990} \\
kNN P. & \textbf{0.1089} & \textbf{0.1648} & \textbf{0.0187} & \textbf{0.3660} & 0.7330 & 0.3370 \\
kNN C. & \textbf{0.1617} & \textbf{0.2210} & \textbf{0.0218} & \textbf{0.4280} & \textbf{0.8409} & 0.4360 \\
CBTf P. & 0.0609 & 0.0951 & 0.0112 & 0.2160 & 0.8323 & 0.5100 \\
CBTf C. & 0.0636 & 0.0996 & 0.0118 & 0.2280 & 0.5220 & 0.2430 \\
CBT P. & 0.0629 & 0.1004 & 0.0121 & 0.2340 & 0.5161 & 0.1540 \\
CBT C. & 0.0578 & 0.0889 & 0.0103 & 0.1980 & 0.5961 & 0.5600 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1057} & \textbf{0.1537} & \textbf{0.0167} & \textbf{0.3260} & \textbf{0.6777} & 0.2260 \\
Random & 0.0065 & 0.0098 & 0.0015 & 0.0220 & \textbf{0.9796} & \textbf{0.9990} \\
kNN P. & \textbf{0.1257} & \textbf{0.1767} & \textbf{0.0183} & \textbf{0.3580} & \textbf{0.7108} & 0.2680 \\
kNN C. & \textbf{0.1434} & \textbf{0.2012} & \textbf{0.0208} & \textbf{0.4080} & \textbf{0.8117} & \textbf{0.3500} \\
CBTf P. & 0.0648 & 0.0986 & 0.0112 & 0.2160 & 0.6538 & 0.2390 \\
CBTf C. & 0.0521 & 0.0859 & 0.0106 & 0.2040 & 0.5274 & 0.1420 \\
CBT P. & 0.0589 & 0.0921 & 0.0109 & 0.2100 & 0.6302 & 0.3060 \\
CBT C. & 0.0489 & 0.0802 & 0.0099 & 0.1900 & 0.4959 & 0.1400 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1055} & \textbf{0.1555} & \textbf{0.0171} & \textbf{0.3340} & 0.6778 & 0.2250 \\
Random & 0.0044 & 0.0092 & 0.0017 & 0.0260 & \textbf{0.9796} & \textbf{0.9990} \\
kNN P. & \textbf{0.1197} & \textbf{0.1746} & \textbf{0.0189} & \textbf{0.3700} & 0.7368 & 0.3310 \\
kNN C. & \textbf{0.1670} & \textbf{0.2258} & \textbf{0.0220} & \textbf{0.4320} & \textbf{0.8223} & 0.3790 \\
CBTf P. & 0.0539 & 0.0854 & 0.0102 & 0.1960 & 0.5836 & 0.2560 \\
CBTf C. & 0.0606 & 0.0963 & 0.0115 & 0.2220 & 0.5054 & 0.1350 \\
CBT P. & 0.0604 & 0.0898 & 0.0100 & 0.1920 & 0.7932 & 0.4460 \\
CBT C. & 0.0570 & 0.0914 & 0.0110 & 0.2120 & 0.4967 & 0.1390 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Netflix Prize (Dense), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 20M $\rightarrow$ Netflix Prize (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0546 $\pm$ 0.0040 & \\
\hline
Random & 0.0063 $\pm$ 0.0014 & True \\
TopPop & 0.1079 $\pm$ 0.0032 & True \\
kNN P. & 0.1181 $\pm$ 0.0070 & True \\
kNN C. & 0.1573 $\pm$ 0.0101 & True \\
CBTf P. & 0.0599 $\pm$ 0.0045 & False \\
CBTf C. & 0.0588 $\pm$ 0.0048 & True \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0607 $\pm$ 0.0016 & \\
\hline
Random & 0.0063 $\pm$ 0.0014 & True \\
TopPop & 0.1079 $\pm$ 0.0032 & True \\
kNN P. & 0.1181 $\pm$ 0.0070 & True \\
kNN C. & 0.1573 $\pm$ 0.0101 & True \\
CBTf P. & 0.0599 $\pm$ 0.0045 & False \\
CBTf C. & 0.0588 $\pm$ 0.0048 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Netflix Prize (Dense), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{MovieLens 20M $\rightarrow$ Netflix Prize (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1512} & \textbf{0.2184} & \textbf{0.0229} & \textbf{0.4580} & \textbf{0.5231} & 0.1060 \\
Random & 0.0014 & 0.0036 & 0.0006 & 0.0120 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.1597} & \textbf{0.2290} & \textbf{0.0238} & \textbf{0.4760} & \textbf{0.5794} & \textbf{0.1430} \\
kNN C. & \textbf{0.1905} & \textbf{0.2639} & \textbf{0.0263} & \textbf{0.5260} & \textbf{0.6681} & \textbf{0.1920} \\
CBTf P. & 0.1305 & 0.1849 & 0.0188 & 0.3760 & 0.4888 & 0.1360 \\
CBTf C. & 0.1314 & 0.1867 & 0.0190 & 0.3800 & 0.4466 & 0.0780 \\
CBT P. & 0.0843 & 0.1020 & 0.0081 & 0.1620 & 0.2108 & 0.0380 \\
CBT C. & 0.1101 & 0.1433 & 0.0128 & 0.2560 & 0.3036 & 0.0440 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1652} & \textbf{0.2344} & \textbf{0.0241} & \textbf{0.4820} & \textbf{0.5234} & 0.1050 \\
Random & 0.0016 & 0.0038 & 0.0006 & 0.0120 & \textbf{0.9797} & \textbf{1.0000} \\
kNN P. & \textbf{0.1744} & \textbf{0.2453} & \textbf{0.0248} & \textbf{0.4960} & \textbf{0.5724} & 0.1390 \\
kNN C. & \textbf{0.1972} & \textbf{0.2706} & \textbf{0.0266} & \textbf{0.5320} & \textbf{0.5931} & 0.1220 \\
CBTf P. & 0.1394 & 0.1939 & 0.0193 & 0.3860 & 0.4762 & 0.1420 \\
CBTf C. & 0.1421 & 0.1971 & 0.0195 & 0.3900 & 0.4473 & 0.0780 \\
CBT P. & 0.0944 & 0.1200 & 0.0102 & 0.2040 & 0.2630 & 0.0400 \\
CBT C. & 0.1081 & 0.1416 & 0.0128 & 0.2560 & 0.3020 & 0.0470 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1401} & \textbf{0.2064} & \textbf{0.0223} & \textbf{0.4460} & \textbf{0.5231} & 0.1100 \\
Random & 0.0047 & 0.0061 & 0.0006 & 0.0120 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.1469} & \textbf{0.2100} & \textbf{0.0218} & \textbf{0.4360} & \textbf{0.6111} & 0.1550 \\
kNN C. & \textbf{0.1665} & \textbf{0.2312} & \textbf{0.0230} & \textbf{0.4600} & \textbf{0.5961} & 0.1220 \\
CBTf P. & 0.1081 & 0.1572 & 0.0164 & 0.3280 & 0.4789 & 0.1540 \\
CBTf C. & 0.1057 & 0.1538 & 0.0161 & 0.3220 & 0.4980 & 0.2490 \\
CBT P. & 0.0822 & 0.1119 & 0.0107 & 0.2140 & 0.3496 & 0.0610 \\
CBT C. & 0.0837 & 0.1127 & 0.0106 & 0.2120 & 0.2989 & 0.0410 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Netflix Prize (Sparse), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{MovieLens 20M $\rightarrow$ Netflix Prize (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.1006 $\pm$ 0.0120 & \\
\hline
Random & 0.0026 $\pm$ 0.0015 & True \\
TopPop & 0.1522 $\pm$ 0.0103 & True \\
kNN P. & 0.1604 $\pm$ 0.0112 & True \\
kNN C. & 0.1847 $\pm$ 0.0132 & True \\
CBTf P. & 0.1260 $\pm$ 0.0132 & True \\
CBTf C. & 0.1264 $\pm$ 0.0153 & True \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0870 $\pm$ 0.0053 & \\
\hline
Random & 0.0026 $\pm$ 0.0015 & True \\
TopPop & 0.1522 $\pm$ 0.0103 & True \\
kNN P. & 0.1604 $\pm$ 0.0112 & True \\
kNN C. & 0.1847 $\pm$ 0.0132 & True \\
CBTf P. & 0.1260 $\pm$ 0.0132 & True \\
CBTf C. & 0.1264 $\pm$ 0.0153 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Netflix Prize (Sparse), with MovieLens 20M as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ Amazon Movies TV Series (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0119 & 0.0203 & 0.0026 & 0.0520 & 0.3381 & 0.0710 \\
Random & 0.0037 & 0.0074 & 0.0011 & 0.0220 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0221} & \textbf{0.0368} & \textbf{0.0045} & \textbf{0.0900} & 0.7904 & 0.5150 \\
kNN C. & \textbf{0.0379} & \textbf{0.0617} & \textbf{0.0074} & \textbf{0.1480} & 0.8939 & 0.6190 \\
CBTf P. & 0.0047 & 0.0098 & 0.0014 & 0.0280 & 0.8367 & 0.8500 \\
CBTf C. & 0.0093 & 0.0148 & 0.0018 & 0.0360 & 0.2683 & 0.0600 \\
CBT P. & 0.0138 & 0.0246 & 0.0032 & 0.0640 & 0.9073 & 0.8580 \\
CBT C. & 0.0089 & 0.0147 & 0.0018 & 0.0360 & 0.2809 & 0.0580 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & 0.0102 & 0.0220 & 0.0033 & 0.0660 & 0.3370 & 0.0710 \\
Random & 0.0072 & 0.0148 & 0.0021 & 0.0420 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0245} & \textbf{0.0423} & \textbf{0.0054} & \textbf{0.1080} & 0.7202 & 0.4830 \\
kNN C. & \textbf{0.0556} & \textbf{0.0797} & \textbf{0.0083} & \textbf{0.1660} & \textbf{0.9586} & \textbf{0.9400} \\
CBTf P. & 0.0113 & 0.0190 & 0.0024 & 0.0480 & 0.9477 & 0.8650 \\
CBTf C. & 0.0101 & 0.0170 & 0.0021 & 0.0420 & 0.2419 & 0.0570 \\
CBT P. & 0.0191 & 0.0321 & 0.0040 & 0.0800 & 0.8151 & 0.6830 \\
CBT C. & 0.0109 & 0.0169 & 0.0019 & 0.0380 & 0.6780 & 0.5530 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0204} & \textbf{0.0304} & \textbf{0.0033} & \textbf{0.0660} & 0.3348 & 0.0700 \\
Random & 0.0030 & 0.0078 & 0.0013 & 0.0260 & \textbf{0.9798} & \textbf{1.0000} \\
kNN P. & \textbf{0.0265} & \textbf{0.0417} & \textbf{0.0049} & \textbf{0.0980} & \textbf{0.6336} & 0.2840 \\
kNN C. & \textbf{0.0331} & \textbf{0.0581} & \textbf{0.0075} & \textbf{0.1500} & \textbf{0.8778} & \textbf{0.5780} \\
CBTf P. & 0.0107 & 0.0179 & 0.0022 & 0.0440 & 0.3047 & 0.1040 \\
CBTf C. & 0.0095 & 0.0172 & 0.0023 & 0.0460 & 0.5255 & 0.5700 \\
CBT P. & 0.0114 & 0.0216 & 0.0030 & 0.0600 & 0.2997 & 0.1140 \\
CBT C. & 0.0098 & 0.0174 & 0.0023 & 0.0460 & 0.2548 & 0.0590 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Amazon Movies TV Series (Dense), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ Amazon Movies TV Series (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0099 $\pm$ 0.0008 & \\
\hline
Random & 0.0046 $\pm$ 0.0018 & True \\
TopPop & 0.0142 $\pm$ 0.0044 & False \\
kNN P. & 0.0244 $\pm$ 0.0018 & True \\
kNN C. & 0.0422 $\pm$ 0.0096 & True \\
CBTf P. & 0.0089 $\pm$ 0.0030 & False \\
CBTf C. & 0.0096 $\pm$ 0.0004 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0148 $\pm$ 0.0032 & \\
\hline
Random & 0.0046 $\pm$ 0.0018 & True \\
TopPop & 0.0142 $\pm$ 0.0044 & False \\
kNN P. & 0.0244 $\pm$ 0.0018 & False \\
kNN C. & 0.0422 $\pm$ 0.0096 & True \\
CBTf P. & 0.0089 $\pm$ 0.0030 & False \\
CBTf C. & 0.0096 $\pm$ 0.0004 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Amazon Movies TV Series (Dense), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ Amazon Movies TV Series (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0823} & \textbf{0.1000} & \textbf{0.0083} & \textbf{0.1660} & 0.1884 & 0.0570 \\
Random & 0.0031 & 0.0075 & 0.0012 & 0.0240 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0841} & \textbf{0.1019} & \textbf{0.0083} & \textbf{0.1660} & 0.7379 & \textbf{0.6260} \\
kNN C. & \textbf{0.0911} & \textbf{0.1092} & \textbf{0.0087} & \textbf{0.1740} & 0.4460 & 0.1670 \\
CBTf P. & 0.0206 & 0.0305 & 0.0033 & 0.0660 & 0.7454 & 0.2280 \\
CBTf C. & 0.0090 & 0.0177 & 0.0025 & 0.0500 & 0.6709 & 0.3480 \\
CBT P. & 0.0783 & 0.0906 & 0.0068 & 0.1360 & 0.2160 & 0.0700 \\
CBT C. & 0.0773 & 0.0886 & 0.0065 & 0.1300 & 0.1625 & 0.0610 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.1108} & \textbf{0.1288} & \textbf{0.0098} & \textbf{0.1960} & 0.1914 & 0.0580 \\
Random & 0.0067 & 0.0122 & 0.0016 & 0.0320 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0829} & \textbf{0.0999} & \textbf{0.0081} & \textbf{0.1620} & \textbf{0.7253} & 0.4790 \\
kNN C. & \textbf{0.1129} & \textbf{0.1320} & \textbf{0.0100} & \textbf{0.2000} & 0.4543 & 0.1740 \\
CBTf P. & 0.0125 & 0.0236 & 0.0032 & 0.0640 & 0.6953 & 0.5620 \\
CBTf C. & 0.0181 & 0.0247 & 0.0024 & 0.0480 & 0.1128 & 0.0450 \\
CBT P. & 0.0293 & 0.0553 & 0.0073 & 0.1460 & 0.2258 & 0.0800 \\
CBT C. & 0.0249 & 0.0531 & 0.0079 & 0.1580 & 0.1620 & 0.0620 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0836} & \textbf{0.1042} & \textbf{0.0090} & \textbf{0.1800} & 0.1826 & 0.0580 \\
Random & 0.0043 & 0.0079 & 0.0010 & 0.0200 & \textbf{0.9799} & \textbf{1.0000} \\
kNN P. & \textbf{0.0857} & \textbf{0.1099} & \textbf{0.0097} & \textbf{0.1940} & 0.7174 & \textbf{0.5960} \\
kNN C. & \textbf{0.1002} & \textbf{0.1247} & \textbf{0.0105} & \textbf{0.2100} & 0.5888 & 0.3620 \\
CBTf P. & 0.0105 & 0.0192 & 0.0026 & 0.0520 & 0.7420 & 0.2940 \\
CBTf C. & 0.0157 & 0.0233 & 0.0025 & 0.0500 & 0.1095 & 0.0530 \\
CBT P. & 0.0286 & 0.0418 & 0.0044 & 0.0880 & 0.7644 & 0.5110 \\
CBT C. & 0.0702 & 0.0843 & 0.0068 & 0.1360 & 0.1627 & 0.0580 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on Amazon Movies TV Series (Sparse), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ Amazon Movies TV Series (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0574 $\pm$ 0.0232 & \\
\hline
Random & 0.0047 $\pm$ 0.0015 & False \\
TopPop & 0.0922 $\pm$ 0.0131 & False \\
kNN P. & 0.0843 $\pm$ 0.0012 & False \\
kNN C. & 0.1014 $\pm$ 0.0090 & False \\
CBTf P. & 0.0145 $\pm$ 0.0044 & False \\
CBTf C. & 0.0143 $\pm$ 0.0038 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0454 $\pm$ 0.0232 & \\
\hline
Random & 0.0047 $\pm$ 0.0015 & False \\
TopPop & 0.0922 $\pm$ 0.0131 & False \\
kNN P. & 0.0843 $\pm$ 0.0012 & False \\
kNN C. & 0.1014 $\pm$ 0.0090 & False \\
CBTf P. & 0.0145 $\pm$ 0.0044 & False \\
CBTf C. & 0.0143 $\pm$ 0.0038 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on Amazon Movies TV Series (Sparse), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Dense)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0284} & \textbf{0.0469} & \textbf{0.0058} & \textbf{0.1160} & 0.5164 & 0.1380 \\
Random & 0.0061 & 0.0111 & 0.0015 & 0.0300 & \textbf{0.9797} & \textbf{1.0000} \\
kNN P. & \textbf{0.0333} & \textbf{0.0540} & \textbf{0.0066} & \textbf{0.1320} & 0.6052 & 0.1780 \\
kNN C. & \textbf{0.0509} & \textbf{0.0867} & \textbf{0.0110} & \textbf{0.2200} & \textbf{0.8605} & \textbf{0.5520} \\
CBTf P. & 0.0154 & 0.0286 & 0.0039 & 0.0780 & 0.7685 & 0.5150 \\
CBTf C. & 0.0235 & 0.0378 & 0.0045 & 0.0900 & 0.3630 & 0.0810 \\
CBT P. & 0.0228 & 0.0400 & 0.0052 & 0.1040 & 0.3651 & 0.0800 \\
CBT C. & 0.0232 & 0.0371 & 0.0044 & 0.0880 & 0.3614 & 0.0810 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0354} & \textbf{0.0564} & \textbf{0.0067} & \textbf{0.1340} & 0.5159 & 0.1400 \\
Random & 0.0035 & 0.0061 & 0.0008 & 0.0160 & \textbf{0.9797} & \textbf{1.0000} \\
kNN P. & \textbf{0.0388} & \textbf{0.0611} & \textbf{0.0072} & \textbf{0.1440} & \textbf{0.7246} & 0.3170 \\
kNN C. & \textbf{0.0658} & \textbf{0.0970} & \textbf{0.0105} & \textbf{0.2100} & \textbf{0.8613} & \textbf{0.5010} \\
CBTf P. & 0.0242 & 0.0360 & 0.0041 & 0.0820 & 0.3855 & 0.0900 \\
CBTf C. & 0.0245 & 0.0355 & 0.0039 & 0.0780 & 0.3636 & 0.0820 \\
CBT P. & 0.0255 & 0.0361 & 0.0038 & 0.0760 & 0.5481 & 0.3820 \\
CBT C. & 0.0231 & 0.0336 & 0.0037 & 0.0740 & 0.3591 & 0.0790 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0325} & \textbf{0.0550} & \textbf{0.0069} & \textbf{0.1380} & \textbf{0.5161} & \textbf{0.1370} \\
Random & 0.0049 & 0.0107 & 0.0016 & 0.0320 & \textbf{0.9797} & \textbf{1.0000} \\
kNN P. & \textbf{0.0410} & \textbf{0.0678} & \textbf{0.0084} & \textbf{0.1680} & \textbf{0.6467} & \textbf{0.2380} \\
kNN C. & \textbf{0.0561} & \textbf{0.0904} & \textbf{0.0107} & \textbf{0.2140} & \textbf{0.7975} & \textbf{0.3740} \\
CBTf P. & 0.0295 & 0.0472 & 0.0056 & 0.1120 & 0.4404 & 0.1280 \\
CBTf C. & 0.0262 & 0.0429 & 0.0052 & 0.1040 & 0.3664 & 0.0810 \\
CBT P. & 0.0259 & 0.0419 & 0.0050 & 0.1000 & 0.3675 & 0.0810 \\
CBT C. & 0.0263 & 0.0437 & 0.0054 & 0.1080 & 0.3666 & 0.0790 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on MovieLens Hetrec 2011 (Dense), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Dense)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0242 $\pm$ 0.0015 & \\
\hline
Random & 0.0048 $\pm$ 0.0011 & False \\
TopPop & 0.0321 $\pm$ 0.0029 & False \\
kNN P. & 0.0377 $\pm$ 0.0032 & False \\
kNN C. & 0.0576 $\pm$ 0.0062 & False \\
CBTf P. & 0.0230 $\pm$ 0.0058 & False \\
CBTf C. & 0.0247 $\pm$ 0.0011 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0247 $\pm$ 0.0014 & \\
\hline
Random & 0.0048 $\pm$ 0.0011 & True \\
TopPop & 0.0321 $\pm$ 0.0029 & True \\
kNN P. & 0.0377 $\pm$ 0.0032 & True \\
kNN C. & 0.0576 $\pm$ 0.0062 & True \\
CBTf P. & 0.0230 $\pm$ 0.0058 & False \\
CBTf C. & 0.0247 $\pm$ 0.0011 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on MovieLens Hetrec 2011 (Dense), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Sparse)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0182} & \textbf{0.0294} & \textbf{0.0035} & \textbf{0.0700} & 0.1564 & 0.0440 \\
Random & 0.0041 & 0.0070 & 0.0009 & 0.0180 & \textbf{0.9800} & \textbf{1.0000} \\
kNN P. & \textbf{0.0242} & \textbf{0.0390} & \textbf{0.0046} & \textbf{0.0920} & \textbf{0.8937} & \textbf{0.8250} \\
kNN C. & \textbf{0.0491} & \textbf{0.0772} & \textbf{0.0090} & \textbf{0.1800} & \textbf{0.8601} & \textbf{0.6610} \\
CBTf P. & 0.0165 & 0.0261 & 0.0031 & 0.0620 & 0.5772 & 0.5430 \\
CBTf C. & 0.0128 & 0.0245 & 0.0034 & 0.0680 & 0.1130 & 0.0340 \\
CBT P. & 0.0075 & 0.0157 & 0.0023 & 0.0460 & 0.3317 & 0.1580 \\
CBT C. & 0.0113 & 0.0222 & 0.0031 & 0.0620 & 0.1095 & 0.0370 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0177} & \textbf{0.0297} & \textbf{0.0037} & \textbf{0.0740} & 0.1662 & 0.0440 \\
Random & 0.0051 & 0.0101 & 0.0014 & 0.0280 & \textbf{0.9800} & \textbf{1.0000} \\
kNN P. & \textbf{0.0189} & \textbf{0.0331} & \textbf{0.0043} & \textbf{0.0860} & \textbf{0.8944} & \textbf{0.8120} \\
kNN C. & \textbf{0.0451} & \textbf{0.0697} & \textbf{0.0080} & \textbf{0.1600} & \textbf{0.8870} & \textbf{0.7030} \\
CBTf P. & 0.0165 & 0.0253 & 0.0029 & 0.0580 & 0.4759 & 0.3690 \\
CBTf C. & 0.0144 & 0.0203 & 0.0021 & 0.0420 & 0.0852 & 0.0350 \\
CBT P. & 0.0028 & 0.0057 & 0.0008 & 0.0160 & 0.6735 & 0.2630 \\
CBT C. & 0.0156 & 0.0218 & 0.0022 & 0.0440 & 0.0850 & 0.0340 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0217} & \textbf{0.0347} & \textbf{0.0041} & \textbf{0.0820} & 0.1604 & 0.0450 \\
Random & 0.0026 & 0.0077 & 0.0014 & 0.0280 & \textbf{0.9800} & \textbf{1.0000} \\
kNN P. & \textbf{0.0264} & \textbf{0.0444} & \textbf{0.0055} & \textbf{0.1100} & \textbf{0.9079} & \textbf{0.8420} \\
kNN C. & \textbf{0.0468} & \textbf{0.0735} & \textbf{0.0085} & \textbf{0.1700} & \textbf{0.8596} & \textbf{0.6650} \\
CBTf P. & 0.0153 & 0.0264 & 0.0034 & 0.0680 & 0.5627 & 0.5340 \\
CBTf C. & 0.0136 & 0.0250 & 0.0034 & 0.0680 & 0.1110 & 0.0340 \\
CBT P. & 0.0104 & 0.0172 & 0.0021 & 0.0420 & 0.3511 & 0.1450 \\
CBT C. & 0.0103 & 0.0179 & 0.0023 & 0.0460 & 0.0844 & 0.0340 \\
\hline
\end{tabulary}
\caption{Results of CBT experiment on preprocessed target dataset for cutoff 20 on MovieLens Hetrec 2011 (Sparse), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity. Higher values are better. Best results are in bold.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Sparse)} \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT C. & 0.0124 $\pm$ 0.0023 & \\
\hline
Random & 0.0039 $\pm$ 0.0010 & True \\
TopPop & 0.0192 $\pm$ 0.0018 & False \\
kNN P. & 0.0232 $\pm$ 0.0032 & False \\
kNN C. & 0.0470 $\pm$ 0.0016 & True \\
CBTf P. & 0.0161 $\pm$ 0.0006 & False \\
CBTf C. & 0.0136 $\pm$ 0.0007 & False \\
\hline
\hline
& mAP@20 & Difference is Significant \\
\hline
CBT P. & 0.0069 $\pm$ 0.0031 & \\
\hline
Random & 0.0039 $\pm$ 0.0010 & False \\
TopPop & 0.0192 $\pm$ 0.0018 & True \\
kNN P. & 0.0232 $\pm$ 0.0032 & True \\
kNN C. & 0.0470 $\pm$ 0.0016 & True \\
CBTf P. & 0.0161 $\pm$ 0.0006 & False \\
CBTf C. & 0.0136 $\pm$ 0.0007 & False \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on preprocessed target dataset for mAP@20 differences between CBT and baselines on MovieLens Hetrec 2011 (Sparse), with Netflix Prize as source domain. "P." and "C." stand for Pearson and cosine similarity.}
\end{table}

\clearpage



\section{CBT and LKT-FM: Experiments on Full Target Dataset (Netflix Prize to MovieLens Hetrec 2011)}

The following section covers CBT and LKT-FM ranking experiments performed on the full MovieLens Hetrec 2011 dataset, using Netflix Prize as the source domain.\\
Experiments are run over 10 folds for each combination of source and target domains.\\
The kNN phase is performed with cosine similarity. The metrics of its results are reported with a cutoff of 20.\\
To compare the results, the following baseline recommender systems are used with the same datasets:
\begin{itemize}
\item \textbf{Random}: random items are chosen for recommendation.
\item \textbf{TopPop}: the most popular items are chosen for recommendation.
\item \textbf{kNN}: the same kNN approach used in CBT is applied, without codebook transfer, on the original target dataset. Only cosine similarity is used and bayesian optimization is applied.
\end{itemize}


\subsection{Datasets}

\begin{itemize}
\item \textbf{MovieLens Hetrec 2011} \cite{grouplens, hetrec-2011}: 855,598 ratings by 2,113 users on 10,109 movies, with range 1 to 5.
\item \textbf{Netflix Prize} \cite{netflix-prize-dataset}: 100,480,507 ratings by 480,189 users on 17,770 movies, with range 1 to 5.
\end{itemize}
Netflix Prize is preprocessed to extract a very dense dataset to be used as source domain.\\
Preprocessing of the source domain is performed in multiple iterations. First by removing users with a low amount of interactions, then by removing items with a low amount of interactions. Each missing rating of the source domain is filled with the average of ratings of its user.\\
Finally, the preprocessed and full datasets used in the experiments have the following properties:\\
\begin{center}
\begin{tabulary}{1.0\textwidth}{|L|CCCC|}
\hline
\multicolumn{5}{|c|}{Source Domain} \\
\hline
& Density & Users & Items & Ratings \\
\hline
Netflix Prize & 56.77 & 500 & 500 & 141934 \\
\hline
\hline
\multicolumn{5}{|c|}{Target Domain} \\
\hline
& Density & Users & Items & Ratings \\
\hline
MovieLens Hetrec 2011 & 4.00 & 2113 & 10109 & 855598 \\
\hline
\end{tabulary}
\end{center}
The target dataset is split in train and test sets. To do so, a random rating for each user is removed from the dataset and added to the test set, while the remaining ratings form the train set.


\subsection{Ablation Study}

The ablation study for this experiment is performed in three different ways:
\begin{itemize}
\item \textbf{Source domain mix (CBTmix)}: all the ratings of the source domain are shuffled without keeping rows and column relation.
\item \textbf{Random source domain (CBTrnd)}: a $500 \times 500$ source domain matrix is randomly generated with ratings from 1 to 5.
\item \textbf{Source domain reduction (CBTrem)}: 10\% of the ratings of the source domain are removed before each missing rating is filled with the average of ratings of its user.
\end{itemize}


\subsection{Hyperparameters}

The hyperparameter values are estimated based on the best results of the previous experiments.\\
The following hyperparameters are set:
\begin{itemize}
\item $\texttt{construct\_validation\_every\_n} = 1$: the amount of iterations after which the codebook construction loss is evaluated by the early stopping training for codebook construction.
\item $\texttt{construct\_lower\_validations\_allowed} = 2000$: the amount of consecutive iterations with loss higher than the best one after which the early stopping training for codebook construction stops.
\item $\texttt{maximum\_construct\_iterations} = 20000$: the maximum amount of iterations used for codebook constructions. If the early stopping training reaches this amount, it stops.
\item $\texttt{transfer\_attempts} = 30$: the amount of attempts to find a local minimum for codebook transfer.
\item $\texttt{maximum\_fill\_iterations} = 100$: the maximum amount of iterations used to find a mapping between the target domain and the codebook. The maximum amount is the same for each of the transfer attempts.
\item $\texttt{user\_clusters} = 5$: the amount of user clusters used to build the codebook.
\item $\texttt{item\_clusters} = 5$: the amount of item clusters used to build the codebook.
\item $\texttt{knn\_topk} = 550$: the amount of similar users to consider when computing similarity for kNN.
\item $\texttt{knn\_shrink} = 120$: the shrinkage to apply when computing the similarity for kNN.
\item $\texttt{knn\_similarity} = cosine$: the similarity type to use for kNN.
\item $\texttt{knn\_normalize} = false$: whether to normalize when computing the similarity for kNN. Normalization is computed by dividing the dot product by the product of the norms.
\end{itemize}


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{pictures/movielens-full-target}
\caption{Heatmap of the full MovieLens Hetrec 2011 train set.}
\includegraphics[width=\textwidth]{pictures/movielens-full-target-filled}
\caption{Heatmap of the full MovieLens Hetrec 2011 train set filled with a codebook extracted from the Netflix Prize domain.}
\end{figure}


\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
Fold 1 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0439} & \textbf{0.0659} & \textbf{0.0072} & \textbf{0.1434} & \textbf{0.7849} & 0.0376 \\
Random & 0.0007 & 0.0009 & 0.0001 & 0.0019 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0662} & \textbf{0.0924} & \textbf{0.0092} & \textbf{0.1846} & \textbf{0.9448} & \textbf{0.2198} \\
CBTmix & 0.0100 & 0.0142 & 0.0015 & 0.0293 & 0.5746 & 0.0828 \\
CBTrnd & 0.0103 & 0.0149 & 0.0016 & 0.0317 & 0.5720 & 0.0928 \\
CBTrem & 0.0089 & 0.0153 & 0.0019 & 0.0388 & 0.6000 & 0.0705 \\
CBT & 0.0077 & 0.0116 & 0.0013 & 0.0256 & 0.5841 & 0.0817 \\
LKT-FM & 0.0016 & 0.0030 & 0.0004 & 0.0080 & 0.0062 & 0.0603 \\
\hline
\hline
Fold 2 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0465} & \textbf{0.0687} & \textbf{0.0074} & \textbf{0.1486} & \textbf{0.7850} & 0.0376 \\
Random & 0.0002 & 0.0008 & 0.0001 & 0.0028 & \textbf{0.9980} & \textbf{0.9820} \\
kNN & \textbf{0.0663} & \textbf{0.0930} & \textbf{0.0094} & \textbf{0.1884} & \textbf{0.9448} & \textbf{0.2175} \\
CBTmix & 0.0097 & 0.0145 & 0.0016 & 0.0317 & 0.5891 & 0.0866 \\
CBTrnd & 0.0115 & 0.0162 & 0.0017 & 0.0331 & 0.5718 & 0.0919 \\
CBTrem & 0.0081 & 0.0131 & 0.0016 & 0.0312 & 0.5887 & 0.0645 \\
CBT & 0.0067 & 0.0109 & 0.0013 & 0.0260 & 0.5846 & 0.0816 \\
LKT-FM & 0.0006 & 0.0012 & 0.0002 & 0.0033 & 0.0058 & 0.0664 \\
\hline
\hline
Fold 3 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0586} & \textbf{0.0811} & \textbf{0.0081} & \textbf{0.1619} & \textbf{0.7849} & 0.0375 \\
Random & 0.0002 & 0.0006 & 0.0001 & 0.0024 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0705} & \textbf{0.0967} & \textbf{0.0095} & \textbf{0.1898} & \textbf{0.9451} & \textbf{0.2164} \\
CBTmix & 0.0121 & 0.0176 & 0.0019 & 0.0374 & 0.5896 & 0.0874 \\
CBTrnd & 0.0085 & 0.0139 & 0.0017 & 0.0341 & 0.5713 & 0.0925 \\
CBTrem & 0.0130 & 0.0180 & 0.0018 & 0.0364 & 0.5874 & 0.0638 \\
CBT & 0.0134 & 0.0191 & 0.0020 & 0.0393 & 0.5844 & 0.0806 \\
LKT-FM & 0.0034 & 0.0047 & 0.0005 & 0.0095 & 0.0063 & 0.0684 \\
\hline
\end{tabulary}
\caption{Results of CBT and LKT-FM experiments on full target dataset for cutoff 20 on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity. Higher values are better. Best results are in bold. Folds 1-3.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
Fold 4 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0447} & \textbf{0.0671} & \textbf{0.0074} & \textbf{0.1477} & \textbf{0.7852} & 0.0377 \\
Random & 0.0009 & 0.0012 & 0.0001 & 0.0024 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0656} & \textbf{0.0901} & \textbf{0.0088} & \textbf{0.1770} & \textbf{0.9447} & \textbf{0.2156} \\
CBTmix & 0.0083 & 0.0137 & 0.0017 & 0.0336 & 0.5891 & 0.0847 \\
CBTrnd & 0.0126 & 0.0179 & 0.0019 & 0.0374 & 0.5724 & 0.0908 \\
CBTrem & 0.0087 & 0.0129 & 0.0014 & 0.0284 & 0.5857 & 0.0597 \\
CBT & 0.0087 & 0.0133 & 0.0015 & 0.0303 & 0.5838 & 0.0785 \\
LKT-FM & 0.0004 & 0.0009 & 0.0001 & 0.0024 & 0.0058 & 0.0636 \\
\hline
\hline
Fold 5 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0461} & \textbf{0.0679} & \textbf{0.0073} & \textbf{0.1453} & \textbf{0.7851} & 0.0375 \\
Random & 0.0003 & 0.0009 & 0.0002 & 0.0033 & \textbf{0.9980} & \textbf{0.9823} \\
kNN & \textbf{0.0661} & \textbf{0.0906} & \textbf{0.0088} & \textbf{0.1770} & \textbf{0.9447} & \textbf{0.2146} \\
CBTmix & 0.0097 & 0.0153 & 0.0018 & 0.0360 & 0.5884 & 0.0851 \\
CBTrnd & 0.0100 & 0.0155 & 0.0018 & 0.0355 & 0.5725 & 0.0927 \\
CBTrem & 0.0073 & 0.0123 & 0.0015 & 0.0303 & 0.5854 & 0.0544 \\
CBT & 0.0070 & 0.0119 & 0.0015 & 0.0298 & 0.5856 & 0.0849 \\
LKT-FM & 0.0006 & 0.0009 & 0.0001 & 0.0019 & 0.0060 & 0.0625 \\
\hline
\hline
Fold 6 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0514} & \textbf{0.0723} & \textbf{0.0074} & \textbf{0.1481} & \textbf{0.7851} & 0.0376 \\
Random & 0.0001 & 0.0003 & 0.0000 & 0.0009 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0670} & \textbf{0.0925} & \textbf{0.0093} & \textbf{0.1850} & \textbf{0.9446} & \textbf{0.2149} \\
CBTmix & 0.0108 & 0.0165 & 0.0019 & 0.0374 & 0.5892 & 0.0877 \\
CBTrnd & 0.0088 & 0.0136 & 0.0015 & 0.0308 & 0.5719 & 0.0919 \\
CBTrem & 0.0095 & 0.0153 & 0.0018 & 0.0360 & 0.5872 & 0.0606 \\
CBT & 0.0097 & 0.0141 & 0.0015 & 0.0293 & 0.5873 & 0.0848 \\
LKT-FM & 0.0017 & 0.0035 & 0.0005 & 0.0104 & 0.0060 & 0.0582 \\
\hline
\end{tabulary}
\caption{Results of CBT and LKT-FM experiments on full target dataset for cutoff 20 on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity. Higher values are better. Best results are in bold. Folds 4-6.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
Fold 7 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0468} & \textbf{0.0677} & \textbf{0.0072} & \textbf{0.1434} & \textbf{0.7852} & 0.0378 \\
Random & 0.0007 & 0.0015 & 0.0002 & 0.0043 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0615} & \textbf{0.0869} & \textbf{0.0089} & \textbf{0.1784} & \textbf{0.9446} & \textbf{0.2190} \\
CBTmix & 0.0102 & 0.0146 & 0.0015 & 0.0308 & 0.5897 & 0.0906 \\
CBTrnd & 0.0116 & 0.0173 & 0.0019 & 0.0379 & 0.5719 & 0.0911 \\
CBTrem & 0.0082 & 0.0128 & 0.0015 & 0.0293 & 0.5888 & 0.0652 \\
CBT & 0.0106 & 0.0143 & 0.0014 & 0.0274 & 0.5876 & 0.0833 \\
LKT-FM & 0.0010 & 0.0020 & 0.0003 & 0.0057 & 0.0057 & 0.0582 \\
\hline
\hline
Fold 8 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0515} & \textbf{0.0746} & \textbf{0.0079} & \textbf{0.1585} & \textbf{0.7850} & 0.0378 \\
Random & 0.0001 & 0.0003 & 0.0000 & 0.0009 & \textbf{0.9980} & \textbf{0.9822} \\
kNN & \textbf{0.0678} & \textbf{0.0912} & \textbf{0.0088} & \textbf{0.1765} & \textbf{0.9447} & \textbf{0.2144} \\
CBTmix & 0.0104 & 0.0153 & 0.0017 & 0.0331 & 0.5889 & 0.0859 \\
CBTrnd & 0.0123 & 0.0167 & 0.0016 & 0.0322 & 0.5712 & 0.0900 \\
CBTrem & 0.0084 & 0.0128 & 0.0014 & 0.0284 & 0.5872 & 0.0607 \\
CBT & 0.0088 & 0.0132 & 0.0014 & 0.0289 & 0.5835 & 0.0767 \\
LKT-FM & 0.0014 & 0.0023 & 0.0003 & 0.0057 & 0.0059 & 0.0641 \\
\hline
\hline
Fold 9 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0502} & \textbf{0.0729} & \textbf{0.0077} & \textbf{0.1548} & \textbf{0.7849} & 0.0378 \\
Random & 0.0004 & 0.0008 & 0.0001 & 0.0024 & \textbf{0.9980} & \textbf{0.9821} \\
kNN & \textbf{0.0716} & \textbf{0.0964} & \textbf{0.0093} & \textbf{0.1850} & \textbf{0.9451} & \textbf{0.2203} \\
CBTmix & 0.0094 & 0.0159 & 0.0020 & 0.0398 & 0.5891 & 0.0866 \\
CBTrnd & 0.0124 & 0.0182 & 0.0020 & 0.0393 & 0.5715 & 0.0891 \\
CBTrem & 0.0082 & 0.0132 & 0.0016 & 0.0317 & 0.5841 & 0.0560 \\
CBT & 0.0099 & 0.0142 & 0.0015 & 0.0298 & 0.5833 & 0.0784 \\
LKT-FM & 0.0022 & 0.0027 & 0.0002 & 0.0043 & 0.0056 & 0.0526 \\
\hline
\end{tabulary}
\caption{Results of CBT and LKT-FM experiments on full target dataset for cutoff 20 on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity. Higher values are better. Best results are in bold. Folds 7-9.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CCCCCC|}
\hline
\multicolumn{7}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
Fold 10 & mAP & nDCG & Prec. & Recall & G. Div. & I. Cov. \\
\hline
TopPop & \textbf{0.0494} & \textbf{0.0736} & \textbf{0.0080} & \textbf{0.1609} & \textbf{0.7848} & 0.0379 \\
Random & 0.0002 & 0.0005 & 0.0001 & 0.0014 & \textbf{0.9980} & \textbf{0.9824} \\
kNN & \textbf{0.0696} & \textbf{0.0962} & \textbf{0.0096} & \textbf{0.1917} & \textbf{0.9444} & \textbf{0.2137} \\
CBTmix & 0.0127 & 0.0168 & 0.0016 & 0.0312 & 0.5890 & 0.0865 \\
CBTrnd & 0.0112 & 0.0161 & 0.0017 & 0.0336 & 0.5725 & 0.0923 \\
CBTrem & 0.0117 & 0.0165 & 0.0017 & 0.0336 & 0.5869 & 0.0586 \\
CBT & 0.0076 & 0.0114 & 0.0012 & 0.0246 & 0.5825 & 0.0767 \\
LKT-FM & 0.0019 & 0.0031 & 0.0004 & 0.0076 & 0.0059 & 0.0581 \\
\hline
\end{tabulary}
\caption{Results of CBT and LKT-FM experiments on full target dataset for cutoff 20 on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity. Higher values are better. Best results are in bold. Fold 10.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
& mAP & Difference is Significant \\
\hline
CBT & 0.0090 $\pm$ 0.0019 & \\
\hline
Random & 0.0004 $\pm$ 0.0003 & True \\
TopPop & 0.0489 $\pm$ 0.0041 & True \\
kNN & 0.0672 $\pm$ 0.0027 & True \\
CBTmix & 0.0103 $\pm$ 0.0012 & False \\
CBTrnd & 0.0109 $\pm$ 0.0014 & False \\
CBTrem & 0.0092 $\pm$ 0.0017 & False \\
LKT-FM & 0.0015 $\pm$ 0.0009 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on full target dataset for mAP@20 differences between CBT, LKT-FM and baselines on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
& mAP & Difference is Significant \\
\hline
LKT-FM & 0.0015 $\pm$ 0.0009 & \\
\hline
Random & 0.0004 $\pm$ 0.0003 & True \\
TopPop & 0.0489 $\pm$ 0.0041 & True \\
kNN & 0.0672 $\pm$ 0.0027 & True \\
CBTmix & 0.0103 $\pm$ 0.0012 & True \\
CBTrnd & 0.0109 $\pm$ 0.0014 & True \\
CBTrem & 0.0092 $\pm$ 0.0017 & True \\
CBT & 0.0090 $\pm$ 0.0019 & True \\
\hline
\end{tabulary}
\caption{Significance tests of LKT-FM experiment on full target dataset for mAP@20 differences between CBT, LKT-FM and baselines on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Mixed) $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
& mAP & Difference is Significant \\
\hline
CBTmix & 0.0103 $\pm$ 0.0012 & \\
\hline
Random & 0.0004 $\pm$ 0.0003 & True \\
TopPop & 0.0489 $\pm$ 0.0041 & True \\
kNN & 0.0672 $\pm$ 0.0027 & True \\
CBTrnd & 0.0109 $\pm$ 0.0014 & False \\
CBTrem & 0.0092 $\pm$ 0.0017 & False \\
CBT & 0.0090 $\pm$ 0.0019 & False \\
LKT-FM & 0.0015 $\pm$ 0.0009 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on full target dataset for mAP@20 differences between CBT, LKT-FM and baselines on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is mixed in order to lower the sparsity. Then, the source domain is mixed to perform the ablation study.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Random $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
& mAP & Difference is Significant \\
\hline
CBTrnd & 0.0109 $\pm$ 0.0014 & \\
\hline
Random & 0.0004 $\pm$ 0.0003 & True \\
TopPop & 0.0489 $\pm$ 0.0041 & True \\
kNN & 0.0672 $\pm$ 0.0027 & True \\
CBTmix & 0.0103 $\pm$ 0.0012 & False \\
CBTrem & 0.0092 $\pm$ 0.0017 & False \\
CBT & 0.0090 $\pm$ 0.0019 & False \\
LKT-FM & 0.0015 $\pm$ 0.0009 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on full target dataset for mAP@20 differences between CBT, LKT-FM and baselines on MovieLens Hetrec 2011 (Full). The source domain is randomly generated to perform the ablation study.}
\end{table}

\begin{table}[hbt]
\centering
\begin{tabulary}{\textwidth}{|L|CC|}
\hline
\multicolumn{3}{|c|}{Netflix Prize (Removal) $\rightarrow$ MovieLens Hetrec 2011 (Full)} \\
\hline
\hline
& mAP & Difference is Significant \\
\hline
CBTrem & 0.0092 $\pm$ 0.0017 & \\
\hline
Random & 0.0004 $\pm$ 0.0003 & True \\
TopPop & 0.0489 $\pm$ 0.0041 & True \\
kNN & 0.0672 $\pm$ 0.0027 & True \\
CBTmix & 0.0103 $\pm$ 0.0012 & False \\
CBTrnd & 0.0109 $\pm$ 0.0014 & False \\
CBT & 0.0090 $\pm$ 0.0019 & False \\
LKT-FM & 0.0015 $\pm$ 0.0009 & True \\
\hline
\end{tabulary}
\caption{Significance tests of CBT experiment on full target dataset for mAP@20 differences between CBT, LKT-FM and baselines on MovieLens Hetrec 2011 (Full), with Netflix Prize as source domain. The source domain is reduced in order to lower the sparsity. Then, random ratings removal is applied to the source domain to perform the ablation study.}
\end{table}
